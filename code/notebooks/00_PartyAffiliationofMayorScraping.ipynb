{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d9320f-2bc4-4e07-adeb-cde8b813ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the HTML file\n",
    "html_file = \"Largest cities in the United States by population - Ballotpedia.html\"  # Your file name\n",
    "\n",
    "# Open the file and parse with BeautifulSoup\n",
    "with open(html_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "# Step 2: Locate the correct table based on inspection\n",
    "tables = soup.find_all(\"table\")  # Find all tables in the HTML\n",
    "print(f\"Found {len(tables)} tables in the HTML document.\")\n",
    "correct_table = tables[1]  # Adjust this index as necessary to target the correct table\n",
    "\n",
    "# Step 3: Extract headers from the correct table\n",
    "header_row = correct_table.find_all(\"tr\")[1]  # First row contains the headers\n",
    "headers = [header.text.strip() for header in header_row.find_all(\"th\")]\n",
    "\n",
    "# Ensure that the table title is not part of the headers\n",
    "if \"100 Largest Cities By Population\" in headers:\n",
    "    headers.remove(\"100 Largest Cities By Population\")\n",
    "\n",
    "print(f\"Extracted Headers: {headers}\")\n",
    "\n",
    "# Step 4: Extract all rows of data\n",
    "rows = []\n",
    "for row in correct_table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "    cells = row.find_all(\"td\")  # Data cells\n",
    "    row_data = [cell.text.strip() for cell in cells]\n",
    "    if len(row_data) == len(headers):  # Ensure row matches the number of headers\n",
    "        rows.append(row_data)\n",
    "\n",
    "# Step 5: Create a DataFrame\n",
    "df = pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file\n",
    "output_file = \"mayors_100_largest_cities_fixed.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Data has been saved to '{output_file}'.\")\n",
    "\n",
    "# Step 7: Preview the DataFrame\n",
    "display(df.head(101))  # Preview the first 10 rows\n",
    "print(f\"Total rows extracted: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe35e9-35dc-4bd4-85ff-b9c19f479104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the HTML file\n",
    "html_file = \"Largest cities in the United States by population - Ballotpedia.html\"  # Your file name\n",
    "\n",
    "# Open the file and parse with BeautifulSoup\n",
    "with open(html_file, \"r\", encoding=\"utf-8\") as file:\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "# Step 2: Locate the correct table based on inspection\n",
    "tables = soup.find_all(\"table\")  # Find all tables in the HTML\n",
    "correct_table = tables[1]  # Assuming table index 1 is the correct table\n",
    "\n",
    "# Step 3: Extract all rows of data\n",
    "rows = []\n",
    "for row in correct_table.find_all(\"tr\")[1:]:  # Skip the header row\n",
    "    cells = row.find_all(\"td\")\n",
    "    row_data = [cell.text.strip() for cell in cells]\n",
    "    if len(row_data) > 0:  # Skip empty rows\n",
    "        rows.append(row_data)\n",
    "\n",
    "# Step 4: Extract Mayor and Party Affiliation\n",
    "mayor_party_data = []\n",
    "for row in rows:\n",
    "    mayor = row[3]  # Mayor column (4th column in the table)\n",
    "    if \"(\" in mayor:  # Check if a party affiliation is present\n",
    "        name, affiliation = mayor.rsplit(\"(\", 1)\n",
    "        name = name.strip()  # Extract mayor's name\n",
    "        affiliation = affiliation.strip(\")\").strip()  # Extract party symbol\n",
    "    else:\n",
    "        name = mayor\n",
    "        affiliation = \"Unknown\"  # If no symbol, mark as unknown\n",
    "\n",
    "    # Translate party symbols to full names\n",
    "    party_fullname = {\n",
    "        \"D\": \"Democrat\",\n",
    "        \"R\": \"Republican\",\n",
    "        \"I\": \"Independent\",\n",
    "        \"L\": \"Libertarian\",\n",
    "        \"Unknown\": \"Unknown\",\n",
    "        \"Nonpartisan\": \"Nonpartisan\"\n",
    "    }.get(affiliation, \"Unknown\")\n",
    "\n",
    "    mayor_party_data.append({\"Mayor\": name, \"Party Affiliation\": party_fullname})\n",
    "\n",
    "# Step 5: Create a DataFrame\n",
    "df = pd.DataFrame(mayor_party_data)\n",
    "\n",
    "# Step 6: Save the DataFrame to a CSV file\n",
    "output_file = \"mayors_party_affiliation.csv\"\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"Data has been saved to '{output_file}'.\")\n",
    "\n",
    "# Step 7: Preview the DataFrame\n",
    "display(df.head(101))  # Preview the first 10 rows\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
